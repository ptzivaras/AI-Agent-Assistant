# AI FastAPI Project
Î£Îµ ÏƒÏ…Î½ÎµÏ‡Î· ÏƒÎºÎµÏˆÎ· Ï„Î¹ Î½Î± Ï†Ï„Î¹Î±Î¾Ï‰ Î³Î¹Î±Ï„Î¹ Ï€Ï‰Ï‚ Î½Î± ÎµÎ¹Î½Î±Î¹ Î¤ÎŸÎ  ÎµÏ€Î¹Ï€ÎµÎ´Î¿ ÎºÎ±Î¹ Î½Î± Î¼Î±Î¸Ï‰ ÎºÎ±Ï„Î¹ Î¿Ï…ÏƒÎ¹Î±ÏƒÏ„Î¹ÎºÎ¿! ÎšÎ±Î½Ï‰ Î¼ÎµÎ»ÎµÏ„Î· ÎºÎ±Î¹ÏÎ¿ Ï„Ï‰ÏÎ± Ï„Î¹ ÎºÎ±Î¹ Ï€Ï‰Ï‚! Î˜Î± ÎºÎ±Î½Ï‰ ÏƒÎ¹Î³Î¿Ï…ÏÎ± Version1 ÎºÎ±Î¹ Version 2 ÎºÎ±Î¹ Ï€Î¹Î¿ Î¼ÎµÏ„Î± Ï„Î± Î±Î»Î»Î±.

Nexus-ai is an AI Assistant Agent that Connects FastApi Postgres and AI!!

## Technology
Postgres
Maybe React
FastApi(Python v 3.12"stable")

## Features:
ğŸ”¹DashBoard(React-Axios-Table view)
-Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ tickets
-Î¦Î¹Î»Ï„ÏÎ¬ÏÎµÎ¹ Î±Î½Î¬ category
-Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ similarity matches
This will be very simple not UI Awesome!
ğŸ”¹Add BackEnd..

## Done
Basic FastApi setup (main.py, requirements.txt)
PostgreSQL connection
Simple AI endpoint(mock response)
start doing features

## Versions & DeadLines 
### Each time i apply different concepts from AI agent Theory in project.
Version 1: AI Classification
(User ÏƒÏ„Î­Î»Î½ÎµÎ¹ Ï€ÏÏŒÎ²Î»Î·Î¼Î± â†’ AI ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ structured JSON â†’ Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î¿ DB.)
-API Endpoints
POST /tickets
GET /tickets
GET /tickets/{id}
-AI Layer
Prompt template
JSON structured output
Validation (Pydantic)
Retry on invalid JSON
Confidence score
-Database
Table: tickets
--id
--user_message
--category
--urgency
--sentiment
--confidence
--ai_raw_response
--model_version
--created_at
-Engineering Features
Logging prompt + response
Error handling
Async LLM call
Clean architecture (router â†’ service â†’ repository)
(Î•ÏÏ‰Ï„Î·ÏƒÎµÎ¹Ï‚ Ï€Î¿Ï… Î¸Î± ÎºÎ±Î½Ï‰ ÏƒÏ„Î¿Î½ ÎµÎ±Ï…Ï„Î¿ Î¼Î¿Ï…)
1. ÎÎ­ÏÎµÎ¹Ï‚ structured extraction Î¼Îµ ÏƒÏ‰ÏƒÏ„Î¿ Ï„ÏÎ¿Ï€Î¿ Î· Ï„Î·Î½ ÎµÎºÎ±Î½Î± Î»Î±Î¸Î¿Ï‚ ÎµÎ´Ï‰ Î³Î¹Î±Ï„Î¹?
2. Î•Î¹Î½Î±Î¹ Î±Ï…Ï„Î¿ Ï„Î¿ AI ÏƒÎµ production-like flow Î· Î¿Ï‡Î¹?
3. Î•Î¼Ï€Î¹ÏƒÏ„ÎµÏÎµÏ„Î·ÎºÎ± Ï„Ï…Ï†Î»Î¬ Ï„Î¿ LLM Î· Î¿Ï‡Î¹?

Version 2: Database Integration
(Î•ÏÏ‰Ï„Î·ÏƒÎµÎ¹Ï‚ Ï€Î¿Ï… Î¸Î± ÎºÎ±Î½Ï‰ ÏƒÏ„Î¿Î½ ÎµÎ±Ï…Ï„Î¿ Î¼Î¿Ï…)
Î•Î¹Î½Î±Î¹ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¿ Î±Ï…Ï„Î¿ Î³Î¹Î± Î‘Î™ Î· Ï„Î¿ Î¹Î´Î¹Î¿ Î¿Ï€Ï‰Ï‚ Ï€Î±Î½Ï„Î±?

Feature 3: RAG Implementation(AI + RAG)
-- ÎÎ­Î± Features
Embeddings
Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± embedding Î³Î¹Î± ÎºÎ¬Î¸Îµ ticket
Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÎµ pgvector
Similarity Search
ÎŒÏ„Î±Î½ Î­ÏÏ‡ÎµÏ„Î±Î¹ Î½Î­Î¿ ticket:
Î²ÏÎ¯ÏƒÎºÎµÎ¹Ï‚ 3 Ï€Î±ÏÏŒÎ¼Î¿Î¹Î±
Ï„Î± Î²Î¬Î¶ÎµÎ¹Ï‚ ÏƒÏ„Î¿ prompt
Context Injection
Prompt:
â€œBased on similar past issues: â€¦â€
Database
ÎÎ­Î¿Ï‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚:
ticket_embeddings
vector column
Endpoint
POST /tickets/with-context

(Î•ÏÏ‰Ï„Î·ÏƒÎµÎ¹Ï‚ Ï€Î¿Ï… Î¸Î± ÎºÎ±Î½Ï‰ ÏƒÏ„Î¿Î½ ÎµÎ±Ï…Ï„Î¿ Î¼Î¿Ï…)
ÎšÎ±Ï„Î±Î»Î±Î²Î±Î¯Î½ÎµÎ¹Ï‚ RAG ÏƒÏ‰ÏƒÏ„Î± Î· Î¿Ï‡Î¹?
ÎÎ­ÏÏ‰ embeddings Ï€Î»ÎµÎ¿Î½ Î· Î¿Ï‡Î¹? Î¼Î·Ï€Ï‰Ï‚ Î´ÎµÎ½ Ï„Î± ÎºÎ±Î½Ï‰ ÏƒÏ‰ÏƒÏ„Î±?
ÎÎ­ÏÎµÎ¹Ï‚ vector search Î· Î¿Ï‡Î¹ Î¼Îµ Ï„Î¿ ÏƒÏ‰ÏƒÏ„Î¿ Ï„ÏÎ¿Ï€Î¿?
ÎÎ­ÏÎµÎ¹Ï‚ knowledge grounding Î· Î¿Ï‡Î¹ Î¼Îµ Ï„Î¿ ÏƒÏ‰ÏƒÏ„Î¿ Ï„ÏÎ¿Ï€Î¿?

Version 4? vasika 3 einai  alla exw san 2 to DB integration
-- ÎÎ­Î± Features
Tool Definitions
get_similar_tickets
assign_priority
escalate_ticket
Agent Loop
LLM decides tool
Backend executes
Returns result
LLM continues reasoning
Conversation State
session table
message history
Guardrails
Strict JSON schema
Allowed categories only
Output validation
Cost Monitoring
Token usage logging
Model usage stats endpoint

(Î•ÏÏ‰Ï„Î·ÏƒÎµÎ¹Ï‚ Ï€Î¿Ï… Î¸Î± ÎºÎ±Î½Ï‰ ÏƒÏ„Î¿Î½ ÎµÎ±Ï…Ï„Î¿ Î¼Î¿Ï… Î±Î½ Ï„Î± Î¾ÎµÏÏ‰ ÎºÎ±Î»Î± Î· Î¿Ï‡Î¹)
Agent orchestration
Tool calling
State machine thinking
Production AI backend

## AI Flow
Client â†’ FastAPI Router â†’ Service Layer â†’ AI Service
                                    â†“
                                PostgreSQL
                                    â†“
                                pgvector

## Files

## URLs
Frontend: http://localhost:8000
API Docs: http://localhost:8000/docs
Health Check: http://localhost:8000/health

## Check if these are in project
Clean architecture
DTO separation
Logging strategy
Validation layer
RAG pipeline explanation
Error handling
Dockerized setup
README Î¼Îµ architecture diagram

## Todo for production enviroment(from what i can understand for now...)
### Guardrails (Safety Layer)
Î£Ï„Î¿ version1 Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î­Ï‡Ï‰:
1. Strict JSON schema validation
Pydantic model
Î‘Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹ â†’ retry LLM call
Î‘Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹ 2 Ï†Î¿ÏÎ­Ï‚ â†’ fallback response
2. Allowed categories list 
Î .Î§ ALLOWED_CATEGORIES = ["Hardware", "Software", "Billing"]
Î‘Î½ LLM ÎµÏ€Î¹ÏƒÏ„ÏÎ­ÏˆÎµÎ¹: "Networking" â†’ reject â†’ retry with clarification prompt.

Î£Ï„Î¿ version2 Î¼Ï€Î¿ÏÎµÎ¯Ï‚ Î½Î± Ï€ÏÎ¿ÏƒÎ¸Î­ÏƒÎµÎ¹Ï‚:
Confidence threshold (Ï€.Ï‡. < 0.6 â†’ flag for manual review)
Basic hallucination guard:
Î‘Î½ category Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÏ„Î¿ DB â†’ reject
Input length limits
Basic rate limiting

Î£Ï„Î¿ version3 (serious level):
Output schema enforced via JSON mode
Content filtering
Moderation check
Rule-based override layer

### Cost Monitoring
Î£Ï„Î¿ version1:
Î‘Ï€Î»Î¬ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎµ:
-model_name
-prompt_tokens
-completion_tokens
-total_tokens
-request_time_ms
Î‘Ï…Ï„Î¬ Ï„Î± Ï€Î±Î¯ÏÎ½ÎµÎ¹Ï‚ Î±Ï€ÏŒ Ï„Î¿ LLM API response.

ÎšÎ¬Î½Îµ Î­Î½Î±Î½ Ï€Î¯Î½Î±ÎºÎ±:
ai_usage_logs
- id
- ticket_id
- model
- prompt_tokens
- completion_tokens
- total_tokens
- cost_estimate
- created_at

Î£Ï„Î¿ v2:
ndpoint: /metrics/usage
Î£Ï…Î½Î¿Î»Î¹ÎºÏŒ token usage
Cost estimate Î±Î½Î¬ Î·Î¼Î­ÏÎ±

Î£Ï„Î¿ v3:
Rate limiting per user
Max tokens per request
Cost alert threshold

### Prompt Versioning
Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ advanced Î±Î»Î»Î¬ ÏŒÏ‡Î¹ Î´ÏÏƒÎºÎ¿Î»Î¿.
ÎœÎ·Î½ ÎºÎ¬Î½ÎµÎ¹Ï‚ hardcode prompt string Î¼Î­ÏƒÎ± ÏƒÏ„Î¿Î½ service.

Table: prompt_templates
- id
- name
- version
- template_text
- created_at
- is_active

ÎšÎ±Î¹ ÏƒÏ„Î¿Î½ ticket:
- prompt_version

ÎˆÏ„ÏƒÎ¹ Î¼Ï€Î¿ÏÎµÎ¯Ï‚ Î½Î± Ï€ÎµÎ¹Ï‚: â€œVersion 2 improved urgency detection by 18%â€

## Engineering Decisions
Why structured JSON instead of free text?
Why pgvector instead of external vector DB?
Why retry logic limited to 2 attempts?
Why versioned prompts?
Do I need the following or not?
-Idempotency
-Failure modes
-LLM timeout handling
-Rate limiting strategy

## Test it
cd "e:\1.CodeProjects\AI Agent Assistant\nexus-ai"
python -m uvicorn main:app --reload
pws na testarw swsta ta endpoints?